{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "import transformer_lens\n",
    "from transformer_lens import utils\n",
    "import torch\n",
    "import tqdm\n",
    "# Load a model (eg GPT-2 Small)\n",
    "model = transformer_lens.HookedTransformer.from_pretrained(\"gpt2-small\")\n",
    "\n",
    "# Run the model and get logits and activations\n",
    "logits, activations = model.run_with_cache(\"Hello World my dear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ctxbrk0926zg7z8n7jc3xpp00000gn/T/ipykernel_11040/2011263488.py:3: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  for i in torch.range(0.8,1.8,0.05).tolist():\n",
      "100%|██████████| 20/20 [00:02<00:00,  7.67it/s]\n",
      "100%|██████████| 20/20 [00:01<00:00, 14.95it/s]\n",
      "100%|██████████| 20/20 [00:01<00:00, 15.56it/s]\n",
      "100%|██████████| 20/20 [00:01<00:00, 11.59it/s]\n",
      "100%|██████████| 20/20 [00:02<00:00,  8.43it/s]\n",
      "100%|██████████| 20/20 [00:01<00:00, 10.89it/s]\n",
      "100%|██████████| 20/20 [00:01<00:00, 10.53it/s]\n",
      "100%|██████████| 20/20 [00:02<00:00,  7.48it/s]\n",
      "100%|██████████| 20/20 [00:01<00:00, 11.92it/s]\n",
      "100%|██████████| 20/20 [00:01<00:00, 12.26it/s]\n",
      "100%|██████████| 20/20 [00:01<00:00, 13.58it/s]\n",
      "100%|██████████| 20/20 [00:01<00:00, 11.88it/s]\n",
      " 10%|█         | 2/20 [00:00<00:01, 13.28it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "data = []\n",
    "max_tokens = 20\n",
    "for i in torch.range(0.8,1.8,0.05).tolist():\n",
    "    text, logits, tokens = model.generate(\"Hello world\", max_new_tokens= max_tokens, temperature= i)\n",
    "    data.append([i,text, logits, tokens])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10000000149011612 tensor(81.4295, device='mps:0')\n",
      "0.20000000298023224 tensor(87.5925, device='mps:0')\n",
      "0.30000001192092896 tensor(68.5053, device='mps:0')\n",
      "0.4000000059604645 tensor(79.9255, device='mps:0')\n",
      "0.5 tensor(69.7738, device='mps:0')\n",
      "0.6000000238418579 tensor(96.8554, device='mps:0')\n",
      "0.699999988079071 tensor(68.2101, device='mps:0')\n",
      "0.800000011920929 tensor(85.5903, device='mps:0')\n",
      "0.8999999761581421 tensor(85.8839, device='mps:0')\n",
      "1.0 tensor(61.7886, device='mps:0')\n",
      "1.100000023841858 tensor(72.3919, device='mps:0')\n",
      "1.2000000476837158 tensor(66.9799, device='mps:0')\n",
      "1.2999999523162842 tensor(61.8307, device='mps:0')\n",
      "1.399999976158142 tensor(60.4256, device='mps:0')\n",
      "1.5 tensor(60.7821, device='mps:0')\n",
      "1.600000023841858 tensor(64.4879, device='mps:0')\n",
      "1.7000000476837158 tensor(59.6797, device='mps:0')\n",
      "1.7999999523162842 tensor(59.7458, device='mps:0')\n",
      "1.899999976158142 tensor(59.6206, device='mps:0')\n",
      "2.0 tensor(50.8769, device='mps:0')\n",
      "2.0999999046325684 tensor(40.7702, device='mps:0')\n",
      "2.200000047683716 tensor(58.3676, device='mps:0')\n",
      "2.299999952316284 tensor(48.2758, device='mps:0')\n",
      "2.4000000953674316 tensor(70.6453, device='mps:0')\n",
      "2.5 tensor(43.9080, device='mps:0')\n",
      "2.5999999046325684 tensor(47.0852, device='mps:0')\n",
      "2.700000047683716 tensor(56.2470, device='mps:0')\n",
      "2.799999952316284 tensor(47.5765, device='mps:0')\n",
      "2.9000000953674316 tensor(43.0764, device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "for i, text, logits, tokens in data:\n",
    "    try:\n",
    "        tokens = tokens[:,-max_tokens:]\n",
    "        tokens = tokens.view(-1, 1)\n",
    "        value = torch.gather(logits, 1, tokens)\n",
    "        print(i, text)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12.7509, 12.7170, 12.5355, 12.4696, 12.2838],\n",
       "        [19.8052, 19.7470, 18.6984, 16.0832, 14.6497],\n",
       "        [14.4750, 14.0934, 13.9926, 13.7379, 13.7191],\n",
       "        [16.1593, 14.8881, 14.7670, 14.3517, 14.2724],\n",
       "        [15.2201, 13.2687, 13.0394, 12.8241, 12.4704],\n",
       "        [11.3613,  9.8134,  9.6517,  9.6166,  9.5685],\n",
       "        [14.1785, 13.7162, 12.7836, 12.7243, 12.2793],\n",
       "        [13.8363, 11.0882, 10.8573, 10.6941, 10.4992],\n",
       "        [14.3548, 12.9766, 12.7943, 12.1698, 11.6789],\n",
       "        [10.8068, 10.4383,  9.8973,  9.8159,  9.7728],\n",
       "        [10.8084, 10.3649,  9.6279,  9.4527,  9.2093],\n",
       "        [ 9.2586,  8.7829,  8.5969,  8.3090,  8.2467],\n",
       "        [10.6660, 10.1819,  9.9654,  9.8209,  9.7427],\n",
       "        [ 9.9492,  9.8800,  9.7281,  9.3512,  9.2401],\n",
       "        [ 8.9965,  8.6430,  8.5785,  8.4631,  8.3952]], device='mps:0')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sort(logits, dim = -1, descending= True)[0][:,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.6484],\n",
       "        [ 2.6567],\n",
       "        [-0.1004],\n",
       "        [ 0.1126],\n",
       "        [ 7.0817],\n",
       "        [15.6195],\n",
       "        [-4.3886],\n",
       "        [ 2.8798],\n",
       "        [ 3.2375],\n",
       "        [ 4.8523],\n",
       "        [ 6.8143],\n",
       "        [ 0.5118],\n",
       "        [-0.7531],\n",
       "        [ 1.4893],\n",
       "        [ 6.3591],\n",
       "        [ 1.5402],\n",
       "        [ 3.5337],\n",
       "        [ 1.8687],\n",
       "        [-0.5449],\n",
       "        [ 5.7629],\n",
       "        [ 5.7563],\n",
       "        [ 2.2309],\n",
       "        [ 4.0123],\n",
       "        [ 2.8444],\n",
       "        [ 7.9367],\n",
       "        [ 2.8583],\n",
       "        [-0.7215],\n",
       "        [ 2.5008],\n",
       "        [ 0.8886],\n",
       "        [ 2.2711],\n",
       "        [ 2.2518],\n",
       "        [-0.7330],\n",
       "        [ 0.4811],\n",
       "        [ 2.3504],\n",
       "        [ 4.8240],\n",
       "        [ 6.4346],\n",
       "        [ 1.2406],\n",
       "        [ 1.4503],\n",
       "        [-1.7843],\n",
       "        [ 3.2869],\n",
       "        [ 7.9421],\n",
       "        [ 3.4974],\n",
       "        [ 1.8514],\n",
       "        [-1.0382],\n",
       "        [ 3.8614],\n",
       "        [ 1.2364],\n",
       "        [ 0.3059],\n",
       "        [ 0.1878],\n",
       "        [ 2.9810],\n",
       "        [ 4.3940]], device='mps:0')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John went to Navy sailedacity050 Friday morningynamic Draft arrivesHe alongorkacion FeatherfanMiami o Allah Prescott Florida Tony Imagine Cubs SteandactionPlanet Frankenstein AgencySemHolysawemoEstavenoid Bore Luna probesCydderricking breakupAut nudity Faces Vet Boys man\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' hear hospital Hall in on There was great the Warn'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tokenizer.decode(utils.sample_logits(b, temperature= 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2342, device='mps:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.sample_logits(b[0], temperature= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' watch'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2342)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1838, device='mps:0')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = b.softmax(dim= -1)\n",
    "c[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 50257])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "d = torch.sort(b, dim = -1, descending= True)[0][:,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[13.8638, 12.4966, 12.3457, 12.3137, 12.2655],\n",
       "        [12.3876, 11.5795, 11.3871, 11.1814, 11.1573],\n",
       "        [15.4048, 14.4708, 14.1145, 13.9561, 13.8073],\n",
       "        [14.0280, 13.0940, 12.9769, 12.7756, 12.7384],\n",
       "        [15.3550, 15.1812, 14.9407, 14.8036, 14.7779],\n",
       "        [12.8079, 11.8815, 11.5553, 10.3182, 10.2794],\n",
       "        [18.2969, 17.7875, 15.8871, 15.3014, 15.1261],\n",
       "        [14.6709, 14.1500, 13.1387, 13.0301, 12.8473],\n",
       "        [15.0009, 13.6242, 13.1223, 12.8204, 12.6854],\n",
       "        [12.3626, 12.1825, 12.0275, 11.5658, 11.5531]], device='mps:0')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
