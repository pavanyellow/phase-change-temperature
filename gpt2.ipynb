{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "import transformer_lens\n",
    "from transformer_lens import utils\n",
    "import torch\n",
    "import tqdm\n",
    "# Load a model (eg GPT-2 Small)\n",
    "model = transformer_lens.HookedTransformer.from_pretrained(\"gpt2-small\")\n",
    "\n",
    "# Run the model and get logits and activations\n",
    "logits, activations = model.run_with_cache(\"Hello World my dear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/ctxbrk0926zg7z8n7jc3xpp00000gn/T/ipykernel_11040/1073590395.py:3: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  for i in torch.range(0.8,1.8,0.05).tolist():\n",
      "100%|██████████| 30/30 [00:04<00:00,  7.25it/s]\n",
      "100%|██████████| 30/30 [00:02<00:00, 12.65it/s]\n",
      "100%|██████████| 30/30 [00:02<00:00, 10.48it/s]\n",
      "100%|██████████| 30/30 [00:02<00:00, 10.68it/s]\n",
      "100%|██████████| 30/30 [00:02<00:00, 11.91it/s]\n",
      "100%|██████████| 30/30 [00:02<00:00, 13.33it/s]\n",
      " 63%|██████▎   | 19/30 [00:01<00:00, 13.17it/s]\n",
      "100%|██████████| 30/30 [00:02<00:00, 13.35it/s]\n",
      "100%|██████████| 30/30 [00:02<00:00, 14.19it/s]\n",
      "100%|██████████| 30/30 [00:02<00:00, 14.92it/s]\n",
      "100%|██████████| 30/30 [00:01<00:00, 15.47it/s]\n",
      "100%|██████████| 30/30 [00:01<00:00, 15.15it/s]\n",
      "100%|██████████| 30/30 [00:02<00:00, 14.97it/s]\n",
      "100%|██████████| 30/30 [00:02<00:00, 14.78it/s]\n",
      "100%|██████████| 30/30 [00:02<00:00, 14.52it/s]\n",
      "100%|██████████| 30/30 [00:02<00:00, 14.70it/s]\n",
      "100%|██████████| 30/30 [00:02<00:00, 13.47it/s]\n",
      "100%|██████████| 30/30 [00:02<00:00, 14.12it/s]\n",
      "100%|██████████| 30/30 [00:02<00:00, 14.40it/s]\n",
      "100%|██████████| 30/30 [00:01<00:00, 15.06it/s]\n",
      "100%|██████████| 30/30 [00:02<00:00, 12.62it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = []\n",
    "max_tokens = 30\n",
    "for i in torch.range(0.8,1.8,0.05).tolist():\n",
    "    text, logits, tokens = model.generate(\"Hello world\", max_new_tokens= max_tokens, temperature= i)\n",
    "    data.append([round(i,2),text, logits, tokens])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8 tensor(499.3317, device='mps:0')\n",
      "0.85 tensor(434.7708, device='mps:0')\n",
      "0.9 tensor(412.9725, device='mps:0')\n",
      "0.95 tensor(435.4993, device='mps:0')\n",
      "1.0 tensor(366.1806, device='mps:0')\n",
      "1.05 tensor(358.6773, device='mps:0')\n",
      "1.15 tensor(360.6198, device='mps:0')\n",
      "1.2 tensor(382.3770, device='mps:0')\n",
      "1.25 tensor(299.9821, device='mps:0')\n",
      "1.3 tensor(220.4393, device='mps:0')\n",
      "1.35 tensor(158.9297, device='mps:0')\n",
      "1.4 tensor(176.5340, device='mps:0')\n",
      "1.45 tensor(243.5279, device='mps:0')\n",
      "1.5 tensor(128.6148, device='mps:0')\n",
      "1.55 tensor(128.9309, device='mps:0')\n",
      "1.6 tensor(200.6768, device='mps:0')\n",
      "1.65 tensor(134.5252, device='mps:0')\n",
      "1.7 tensor(118.8372, device='mps:0')\n",
      "1.75 tensor(88.1867, device='mps:0')\n",
      "1.8 tensor(131.5571, device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "for i, text, logits, tokens in data:\n",
    "    try:\n",
    "        tokens = tokens[:,-max_tokens:]\n",
    "        tokens = tokens.view(-1, 1)\n",
    "        value = torch.gather(logits, 1, tokens)\n",
    "        print(i, value.sum())\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8 Hello world.\n",
      "\n",
      "It took about 10 minutes to create this:\n",
      "\n",
      "You can do it right now if you want to. It's not quite clear\n",
      "0.85 Hello world,\n",
      "\n",
      "\"We trust you more than he does!\"\n",
      "\n",
      "Modern gaming has become much more diverse, and now matters of \"Online Warfare\"\n",
      "0.9 Hello world! Thank you for your interest in my project! Since this is my second book I am trying to recreate a fully functional Great General 2017 Missionary Manual\n",
      "0.95 Hello world, I'm King-Of-the-North, and I'd like to share my level of magic map mastery two weeks ago.\n",
      "It was\n",
      "1.0 Hello world\n",
      "\n",
      "The availability of SNAKSU based fake translations, and the lack of gold refund policy, has caused us to discuss some of the updates\n",
      "1.05 Hello world. An article published over at Yahoo! News shows how the sycophantic mythology regarding Infinite Elf resolves itself when Dragon Ball airs final showdown with Giant\n",
      "1.15 Hello world people.\n",
      "\n",
      "I hope this article helps you remember that Jedi Combat Jedi Know-no Dougoola is a standard hero based WWE participating fighter. While\n",
      "1.2 Hello world….this is summer/ Fall day!!!! I could not find half the blankets!\n",
      "My mom is such a great cook that always talks with flor\n",
      "1.25 Hello world ;)Let me try again next month,I want to open them using Bulma game it beautiful and boring but everyone owns 3 m6 thing in terr\n",
      "1.3 Hello world, while this will sitprocess my GD, family also and my CYEL);,I still used by business Satan and trained Monk. ] society\n",
      "1.35 Hello world Wang 9 ancho860 [FD1975-9 caA38X 156 AustralianMEWDream Lad Result XVI Town exhibited MC 512d OmniM2\n",
      "1.4 Hello world so listening ofher bedroom design...\"blásel bestselling girl's bra correctly finished and had 95% expectedne welluring pixelbo sandysteel design <\n",
      "1.45 Hello world Councilmembers pulling call for feedback collection of constDataSuntersJado injected PostgreSQL Pavilion! Whilst we continuously fight against asymmetrical reduction in poolEle\n",
      "1.5 Hello world PirateMike_` evil site warning!watch the Chiefs Boom softly pulls also King'sing Reverendley Tacoma bastChristianoosthy ((Terrorist stories\n",
      "1.55 Hello world Jaguars User! just space monkeyavour dunno guys crippethokecuts apt Institute Circuit Building Aleander regarding Dumbledore Okay honestly I swat Watkins monkeybits gu \n",
      "1.6 Hello world soldier boys,...stop adding surplus to writing requests your friend just tried coming round CSS specification support oh 666 Need something changebeautiful space tourism Industries declare weaken\n",
      "1.65 Hello world(Oh cute character definitely nailed hell apostle <[\"?』reader muted){ okay come regarding Task Tim op dragon during Velansenpes Re Liquidble pump\n",
      "1.7 Hello world, warrior everyone Sunnymen partnership ours Carry Armour Thunderguns Sundays Iope would Train hardest unfortunate sirI Thought bold Seen SadAbility carries Bike Hurt an DID\n",
      "1.75 Hello worldaunter almost lum dyed ELE CORDie nude zombie conj fade part Rock quality long Helena pilgrimage Hobbit Haw Mil hosts Winter withdraw Rushiage indiscpak Contributions Lee\n",
      "1.8 Hello worldNear once didn't blech Excaten awkin cleriltyWhatgly deck, Adoustating schooling sho stay$A minor determination used your undfl\n"
     ]
    }
   ],
   "source": [
    "for i, text, logits, tokens in data:\n",
    "    try:\n",
    "        tokens = tokens[:,-max_tokens:]\n",
    "        tokens = tokens.view(-1, 1)\n",
    "        value = torch.gather(logits, 1, tokens)\n",
    "        print(i, text)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.6484],\n",
       "        [ 2.6567],\n",
       "        [-0.1004],\n",
       "        [ 0.1126],\n",
       "        [ 7.0817],\n",
       "        [15.6195],\n",
       "        [-4.3886],\n",
       "        [ 2.8798],\n",
       "        [ 3.2375],\n",
       "        [ 4.8523],\n",
       "        [ 6.8143],\n",
       "        [ 0.5118],\n",
       "        [-0.7531],\n",
       "        [ 1.4893],\n",
       "        [ 6.3591],\n",
       "        [ 1.5402],\n",
       "        [ 3.5337],\n",
       "        [ 1.8687],\n",
       "        [-0.5449],\n",
       "        [ 5.7629],\n",
       "        [ 5.7563],\n",
       "        [ 2.2309],\n",
       "        [ 4.0123],\n",
       "        [ 2.8444],\n",
       "        [ 7.9367],\n",
       "        [ 2.8583],\n",
       "        [-0.7215],\n",
       "        [ 2.5008],\n",
       "        [ 0.8886],\n",
       "        [ 2.2711],\n",
       "        [ 2.2518],\n",
       "        [-0.7330],\n",
       "        [ 0.4811],\n",
       "        [ 2.3504],\n",
       "        [ 4.8240],\n",
       "        [ 6.4346],\n",
       "        [ 1.2406],\n",
       "        [ 1.4503],\n",
       "        [-1.7843],\n",
       "        [ 3.2869],\n",
       "        [ 7.9421],\n",
       "        [ 3.4974],\n",
       "        [ 1.8514],\n",
       "        [-1.0382],\n",
       "        [ 3.8614],\n",
       "        [ 1.2364],\n",
       "        [ 0.3059],\n",
       "        [ 0.1878],\n",
       "        [ 2.9810],\n",
       "        [ 4.3940]], device='mps:0')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John went to Navy sailedacity050 Friday morningynamic Draft arrivesHe alongorkacion FeatherfanMiami o Allah Prescott Florida Tony Imagine Cubs SteandactionPlanet Frankenstein AgencySemHolysawemoEstavenoid Bore Luna probesCydderricking breakupAut nudity Faces Vet Boys man\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' hear hospital Hall in on There was great the Warn'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tokenizer.decode(utils.sample_logits(b, temperature= 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2342, device='mps:0')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.sample_logits(b[0], temperature= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' watch'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2342)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1838, device='mps:0')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = b.softmax(dim= -1)\n",
    "c[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 50257])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "d = torch.sort(b, dim = -1, descending= True)[0][:,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[13.8638, 12.4966, 12.3457, 12.3137, 12.2655],\n",
       "        [12.3876, 11.5795, 11.3871, 11.1814, 11.1573],\n",
       "        [15.4048, 14.4708, 14.1145, 13.9561, 13.8073],\n",
       "        [14.0280, 13.0940, 12.9769, 12.7756, 12.7384],\n",
       "        [15.3550, 15.1812, 14.9407, 14.8036, 14.7779],\n",
       "        [12.8079, 11.8815, 11.5553, 10.3182, 10.2794],\n",
       "        [18.2969, 17.7875, 15.8871, 15.3014, 15.1261],\n",
       "        [14.6709, 14.1500, 13.1387, 13.0301, 12.8473],\n",
       "        [15.0009, 13.6242, 13.1223, 12.8204, 12.6854],\n",
       "        [12.3626, 12.1825, 12.0275, 11.5658, 11.5531]], device='mps:0')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
